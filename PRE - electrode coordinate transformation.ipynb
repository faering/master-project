{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform Electrode Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "%matplotlib qt\n",
    "%gui qt\n",
    "\n",
    "# own libraries\n",
    "import neuropsy as npsy\n",
    "\n",
    "# standard libraries\n",
    "import numpy as np\n",
    "\n",
    "# load T1, make DIG montage, transform coordinates\n",
    "import nibabel as nib\n",
    "import mne\n",
    "\n",
    "# plotting\n",
    "# import matplotlib.pyplot as plt\n",
    "# import imageio.v2 as io\n",
    "# import imageio.v3 as iio\n",
    "# import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Electrode Coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Transform Coordinates\n",
    "\n",
    "First we load the electrode coordinates for one subject at a time. The coordinates are in scanner RAS space, but to use the coordinates to find labels from the freesurfer parcellation output files - which are in the surface RAS space - we need to transform the elecrode coordinates to the same sruface RAS space.\n",
    "\n",
    "The MNE-Python toolbox has functions to define a montage which we can attach to the _raw_ object in which we store each subject's data, but these functions expect the electrode coordinates to be represented in meters and furthermore when we apply the montage to the _raw_ object, the coordinates will be automatically transformed to the subject's _head_ space. This is done automatically by using the fsaverage brain's fidicuals to estimate the subject specific fidicuals. And furthermore as we need the coordinates to be in the same space as the freesurfer output, we need to transform the coordinates to surface RAS space. As the fsaverage brain is already in MNI305 space, we can use the subject's MNI transform matrix which has been computed along with the freesurfer output files using the _recon-all_ command. Applying the inverse of this transformation will transform the coordinates from MNI305 to surface RAS space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=104, n_times=1018626\n",
      "    Range : 0 ... 1018625 =      0.000 ...  1989.502 secs\n",
      "Ready.\n",
      "Channel types::\tseeg: 104\n",
      "    Smoothing by a factor of 0.9\n"
     ]
    }
   ],
   "source": [
    "# *************** DEFINES ***************\n",
    "# paths\n",
    "path_data       = 'C:/Users/matti/OneDrive/Education/SDC/MasterThesis/master-project/data/preprocessed'\n",
    "subjects_dir    = 'C:/Users/matti/OneDrive/Education/SDC/MasterThesis/master-project/data/subjects'\n",
    "# path_data       = '/mnt/c/Users/matti/OneDrive/Education/SDC/MasterThesis/master-project/data/preprocessed'\n",
    "# subjects_dir    = '/mnt/c/Users/matti/OneDrive/Education/SDC/MasterThesis/master-project/data/subjects'\n",
    "postfix_load    = 'preprocessed'\n",
    "subject_id      = '19'\n",
    "subject         = f'sub{subject_id}'\n",
    "lut_fname       = f'{subjects_dir}/FreeSurferColorLUT.txt'\n",
    "# [INFO] should 3D image files be saved (True/False)\n",
    "save_images     = False\n",
    "display_brain   = True\n",
    "path_images     = 'C:/Users/matti/OneDrive/Education/SDC/MasterThesis/master-project/results/preprocessing/channel labelling/coordinate transformation'\n",
    "\n",
    "\n",
    "# *************** LOAD SUBJECT DATA ***************\n",
    "# load subject data\n",
    "data = npsy.DataHandler(path=path_data, subject_id=subject_id, exp_phase=2, fs=512, verbose=False)\n",
    "data.load(load_saved=True, postfix=postfix_load)\n",
    "data.create_mne_raw()\n",
    "\n",
    "# load subject MRI data\n",
    "T1_fname = ''.join([subjects_dir, '/sub', subject_id, '/mri/T1.mgz'])\n",
    "T1 = nib.load(T1_fname)\n",
    "\n",
    "\n",
    "# *************** LOAD ELECTRODE COORDINATES ***************\n",
    "# electrode coordinates are stored in scanner RAS space\n",
    "coords_ras = []\n",
    "for ch in data.df_chan['name']:\n",
    "    coords_ras.append(data.df_chan.loc[data.df_chan['name'] == ch, ['loc_1', 'loc_2', 'loc_3']].to_numpy()[0])\n",
    "coords_ras = np.asanyarray(coords_ras)\n",
    "\n",
    "# create montage (coordinates are still in scanner RAS space)\n",
    "coords_ras_dict = {key: tuple(values) for key, values in zip(data.df_chan['name'], coords_ras)}\n",
    "montage = mne.channels.make_dig_montage(ch_pos=coords_ras_dict, coord_frame=\"ras\")\n",
    "\n",
    "\n",
    "# *************** DEFINE TRANSFORMATIONS ***************\n",
    "# define transformation matrix from mm to m\n",
    "mm2m = np.eye(4)\n",
    "mm2m[:3, :3] /= 1000\n",
    "mm2m_t = mne.transforms.Transform('ras', 'ras', trans=mm2m)\n",
    "\n",
    "# get transformation matrix from scanner RAS to voxel space\n",
    "ras2vox = T1.header.get_ras2vox()\n",
    "ras2vox[:3, :3] *= 1000  # scale from mm to m\n",
    "ras2vox_t = mne.transforms.Transform(fro=\"ras\", to=\"mri_voxel\", trans=ras2vox)\n",
    "\n",
    "# get transformation matrix from voxel space to freesurfer surface RAS (MRI) space\n",
    "vox2mri = T1.header.get_vox2ras_tkr()\n",
    "vox2mri[:3] /= 1000  # scale from mm to m\n",
    "vox2mri_t = mne.transforms.Transform(fro=\"mri_voxel\", to=\"mri\", trans=vox2mri)\n",
    "\n",
    "# combine transforms to get transformation from scanner RAS to freesurfer surface RAS (MRI) space\n",
    "ras2mri_t = mne.transforms.combine_transforms(ras2vox_t, vox2mri_t, fro=\"ras\", to=\"mri\")\n",
    "\n",
    "# estimate head to surface RAS (MRI) transformation (mainly for visualization)\n",
    "head2mri_t = mne.coreg.estimate_head_mri_t(subject=subject, subjects_dir=subjects_dir)\n",
    "mri2head_t = mne.transforms.invert_transform(head2mri_t)\n",
    "\n",
    "\n",
    "# *************** APPLY TRANSFORMATIONS ***************\n",
    "# first transform coordinates from m to mm\n",
    "montage.apply_trans(mm2m_t)\n",
    "\n",
    "# then transform coordinates from scanner RAS to freesurfer surface RAS (MRI) space\n",
    "montage.apply_trans(ras2mri_t)\n",
    "\n",
    "# transform from surface RAS (MRI) to head space\n",
    "montage.apply_trans(mri2head_t)\n",
    "\n",
    "# apply montage to the raw data\n",
    "data.raw.set_montage(montage)\n",
    "\n",
    "\n",
    "# *************** VISUALIZE ***************\n",
    "if display_brain:\n",
    "    # Areas to highligt in the brain\n",
    "    labels = (\n",
    "        \"HP_head\",\n",
    "        \"HP_body\",\n",
    "        \"HP_tail\"\n",
    "        # 'Right-Hippocampus',\n",
    "    )\n",
    "\n",
    "    # electrodes to highlight\n",
    "    # electrodes = [\"A\", \"B\", \"C\"]\n",
    "    # picks = [\n",
    "    #     ii\n",
    "    #     for ii, ch_name in enumerate(data.raw.ch_names)\n",
    "    #     if any([elec in ch_name for elec in electrodes])]\n",
    "\n",
    "    # colors for the electrode contacts\n",
    "    # [INFO] add the channel names here to plot in a different color\n",
    "    color_picks     = [\"C' 02\"]\n",
    "    # [INFO] set color settings\n",
    "    color_settings  = {\"default\": \"cyan\",   \n",
    "                    \"picks\": \"gold\"}\n",
    "    \n",
    "\n",
    "    ch_names = data.df_chan['name'].to_list()\n",
    "    sensor_colors = np.asanyarray([color_settings['default']] * len(ch_names))\n",
    "    color_idx = np.where(np.isin(ch_names, color_picks))[0]\n",
    "    sensor_colors[color_idx] = color_settings['picks']\n",
    "\n",
    "\n",
    "    # Plot the electrode positions in surface RAS space\n",
    "    fig = mne.viz.plot_alignment(\n",
    "        info=data.raw.info,\n",
    "        trans=head2mri_t,\n",
    "        subject=subject,\n",
    "        subjects_dir=subjects_dir,\n",
    "        surfaces=[],\n",
    "        # sensor_colors='cyan',\n",
    "        sensor_colors=sensor_colors,\n",
    "        coord_frame='mri',\n",
    "        # bgcolor=\"white\"\n",
    "    )\n",
    "\n",
    "    fig.plotter.set_background('white')\n",
    "    # fig.plotter.enable_anti_aliasing()            # Enable anti-aliasing for smoother edges\n",
    "    # fig.plotter.window_size = [1600, 1200]        # Increase the window size for higher rendering quality\n",
    "\n",
    "    # Plot the whole brain in an opaque manner\n",
    "    brain = mne.viz.Brain(\n",
    "        subject=subject,\n",
    "        alpha=0.20,\n",
    "        cortex=\"low_contrast\",\n",
    "        subjects_dir=subjects_dir,\n",
    "        units=\"m\",\n",
    "        figure=fig,\n",
    "        size=(1200, 1200),\n",
    "    )\n",
    "\n",
    "    # Plot the selected brain regions\n",
    "    # brain.add_volume_labels(aseg=\"rh.hippoAmygLabels.HBT.resampled\", labels=labels, lut_fname=lut_fname)\n",
    "    # brain.add_volume_labels(aseg=\"lh.hippoAmygLabels.HBT.resampled\", labels=labels, lut_fname=lut_fname)\n",
    "    brain.add_volume_labels(aseg=\"hippoAmygLabels.HBT.combined\", labels=labels, lut_fname=lut_fname, alpha=0.3)\n",
    "    # brain.add_volume_labels(aseg=\"aparc+aseg\", labels=labels, lut_fname=lut_fname)\n",
    "    if not save_images:\n",
    "        brain.show_view(azimuth=0, elevation=90, distance=0.3)\n",
    "\n",
    "\n",
    "    if save_images:\n",
    "        n_steps = 90 \n",
    "        azimuth_step = 360 / n_steps\n",
    "\n",
    "        # for second in range(n_seconds):\n",
    "        for step in range(n_steps):\n",
    "\n",
    "            # Rotate the brain view\n",
    "            brain.show_view(azimuth=step * azimuth_step, elevation=90, distance=0.35)\n",
    "            \n",
    "            # Save the current frame\n",
    "            img_path = f\"{path_images}/brain gif/frame_{step}.png\"\n",
    "            brain.save_image(img_path)\n",
    "\n",
    "        del brain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Save to File\n",
    "\n",
    "Now that we have the electrode coordinates inoculated in the MNE-Python Raw object along with the iEEG data readings we will save the results. But, saving the coordinates to file will be saved in head space, therefore we also need to save the correct transformation matrices to go from head to surface RAS space - which is referred to as MRI space inside MNE documentation - as we need the coordinates in MRI space to match the freesurfer surface output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reserving possible split file sub19_split-01_ieeg.fif\n",
      "Overwriting existing file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing C:\\Users\\matti\\OneDrive\\Education\\SDC\\MasterThesis\\master-project\\data\\preprocessed\\sub19_ieeg.fif\n",
      "Closing C:\\Users\\matti\\OneDrive\\Education\\SDC\\MasterThesis\\master-project\\data\\preprocessed\\sub19_ieeg.fif\n",
      "[done]\n",
      "Overwriting existing file.\n",
      "Overwriting existing file.\n",
      "Overwriting existing file.\n",
      "Overwriting existing file.\n"
     ]
    }
   ],
   "source": [
    "# save raw\n",
    "data.raw.save(fname=''.join([path_data, '/sub', subject_id, '_ieeg.fif']), \n",
    "              split_naming='bids', \n",
    "              overwrite=True)\n",
    "\n",
    "# save transformations\n",
    "head2mri_t.save(''.join([subjects_dir, '/', subject, '/mri/transforms/t1-head2mri-trans.fif']), overwrite=True)\n",
    "mri2head_t.save(''.join([subjects_dir, '/', subject, '/mri/transforms/t1-mri2head-trans.fif']), overwrite=True)\n",
    "ras2mri_t.save(''.join([subjects_dir, '/', subject, '/mri/transforms/t1-ras2mri-trans.fif']), overwrite=True)\n",
    "mm2m_t.save(''.join([subjects_dir, '/', subject, '/mri/transforms/t1-mm2m-trans.fif']), overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
