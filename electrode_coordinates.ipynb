{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Electrode Coordinates\n",
    "\n",
    "First we load the electrode coordinates for one subject at a time. The coordinates are in scanner RAS space, but to use the coordinates to find labels from the freesurfer parcellation output files - which are in the surface RAS space - we need to transform the elecrode coordinates to the same sruface RAS space.\n",
    "\n",
    "The MNE-Python toolbox has functions to define a montage which we can attach to the _raw_ object in which we store each subject's data, but these functions expect the electrode coordinates to be represented in meters and furthermore when we apply the montage to the _raw_ object, the coordinates will be automatically transformed to the subject's _head_ space. This is done automatically by using the fsaverage brain's fidicuals to estimate the subject specific fidicuals. And furthermore as we need the coordinates to be in the same space as the freesurfer output, we need to transform the coordinates to surface RAS space. As the fsaverage brain is already in MNI305 space, we can use the subject's MNI transform matrix which has been computed along with the freesurfer output files using the _recon-all_ command. Applying the inverse of this transformation will transform the coordinates from MNI305 to surface RAS space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=80, n_times=868110\n",
      "    Range : 0 ... 868109 =      0.000 ...  1695.525 secs\n",
      "Ready.\n",
      "Using pyvistaqt 3d backend.\n",
      "Channel types::\tseeg: 80\n",
      "    Smoothing by a factor of 0.9\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "%gui qt\n",
    "\n",
    "import neuropsy as npsy\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import mne\n",
    "\n",
    "\n",
    "# *************** DEFINES ***************\n",
    "# paths\n",
    "path_data       = 'C:/Users/matti/OneDrive/Education/SDC/MasterThesis/master-project/data/preprocessed'\n",
    "subjects_dir    = 'C:/Users/matti/OneDrive/Education/SDC/MasterThesis/master-project/data/subjects'\n",
    "subject_id      = '04'\n",
    "subject         = f'sub{subject_id}'\n",
    "lut_fname       = f'{subjects_dir}/FreeSurferColorLUT.txt'\n",
    "\n",
    "\n",
    "# *************** LOAD SUBJECT DATA ***************\n",
    "# load subject data\n",
    "data = npsy.DataHandler(path=path_data, subject_id=subject_id, exp_phase=2, fs=512, verbose=False)\n",
    "data.load(load_saved=True, postfix='preprocessed')\n",
    "data.create_raw()\n",
    "\n",
    "# load subject MRI data\n",
    "T1_fname = ''.join([subjects_dir, '/sub', subject_id, '/mri/T1.mgz'])\n",
    "T1 = nib.load(T1_fname)\n",
    "\n",
    "\n",
    "# *************** LOAD ELECTRODE COORDINATES ***************\n",
    "# electrode coordinates are stored in scanner RAS space\n",
    "coords_ras = []\n",
    "for ch in data.df_chan['name']:\n",
    "    coords_ras.append(data.df_chan.loc[data.df_chan['name'] == ch, ['loc_1', 'loc_2', 'loc_3']].to_numpy()[0])\n",
    "coords_ras = np.asanyarray(coords_ras)\n",
    "\n",
    "# create montage (coordinates are still in scanner RAS space)\n",
    "coords_ras_dict = {key: tuple(values) for key, values in zip(data.df_chan['name'], coords_ras)}\n",
    "montage = mne.channels.make_dig_montage(ch_pos=coords_ras_dict, coord_frame=\"ras\")\n",
    "\n",
    "\n",
    "# *************** DEFINE TRANSFORMATIONS ***************\n",
    "# define transformation matrix from mm to m\n",
    "mm2m = np.eye(4)\n",
    "mm2m[:3, :3] /= 1000\n",
    "mm2m_t = mne.transforms.Transform('ras', 'ras', trans=mm2m)\n",
    "\n",
    "# get transformation matrix from scanner RAS to voxel space\n",
    "ras2vox = T1.header.get_ras2vox()\n",
    "ras2vox[:3, :3] *= 1000  # scale from mm to m\n",
    "ras2vox_t = mne.transforms.Transform(fro=\"ras\", to=\"mri_voxel\", trans=ras2vox)\n",
    "\n",
    "# get transformation matrix from voxel space to freesurfer surface RAS (MRI) space\n",
    "vox2mri = T1.header.get_vox2ras_tkr()\n",
    "vox2mri[:3] /= 1000  # scale from mm to m\n",
    "vox2mri_t = mne.transforms.Transform(fro=\"mri_voxel\", to=\"mri\", trans=vox2mri)\n",
    "\n",
    "# combine transforms to get transformation from scanner RAS to freesurfer surface RAS (MRI) space\n",
    "ras2mri_t = mne.transforms.combine_transforms(ras2vox_t, vox2mri_t, fro=\"ras\", to=\"mri\")\n",
    "\n",
    "# estimate head to surface RAS (MRI) transformation (mainly for visualization)\n",
    "head2mri_t = mne.coreg.estimate_head_mri_t(subject=subject, subjects_dir=subjects_dir)\n",
    "mri2head_t = mne.transforms.invert_transform(head2mri_t)\n",
    "\n",
    "\n",
    "# *************** APPLY TRANSFORMATIONS ***************\n",
    "# first transform coordinates from m to mm\n",
    "montage.apply_trans(mm2m_t)\n",
    "\n",
    "# then transform coordinates from scanner RAS to freesurfer surface RAS (MRI) space\n",
    "montage.apply_trans(ras2mri_t)\n",
    "\n",
    "# transform from surface RAS (MRI) to head space\n",
    "montage.apply_trans(mri2head_t)\n",
    "\n",
    "# apply montage to the raw data\n",
    "data.raw.set_montage(montage)\n",
    "\n",
    "\n",
    "# *************** VISUALIZE ***************\n",
    "# Areas to highligt in the brain\n",
    "labels = (\n",
    "    \"HP_head\",\n",
    "    \"HP_body\",\n",
    "    \"HP_tail\"\n",
    "    # 'Right-Hippocampus',\n",
    ")\n",
    "\n",
    "# electrodes to highlight\n",
    "# electrodes = [\"A\", \"B\", \"C\"]\n",
    "# picks = [\n",
    "#     ii\n",
    "#     for ii, ch_name in enumerate(data.raw.ch_names)\n",
    "#     if any([elec in ch_name for elec in electrodes])]\n",
    "\n",
    "# colors for the electrode contacts\n",
    "color_picks     = ['B 02']              # [INFO] add the channel names here to plot in a different color\n",
    "color_settings  = {'default': 'cyan',   # [INFO] set color settings\n",
    "                   'picks': 'gold'}\n",
    "\n",
    "ch_names = data.df_chan['name'].to_list()\n",
    "sensor_colors = np.asanyarray([color_settings['default']] * len(ch_names))\n",
    "color_idx = np.where(np.isin(ch_names, color_ch_names))[0]\n",
    "sensor_colors[color_idx] = color_settings['picks']\n",
    "\n",
    "\n",
    "# Plot the electrode positions in surface RAS space\n",
    "fig = mne.viz.plot_alignment(\n",
    "    info=data.raw.info,\n",
    "    trans=head2mri_t,\n",
    "    subject=subject,\n",
    "    subjects_dir=subjects_dir,\n",
    "    surfaces=[],\n",
    "    # sensor_colors='cyan',\n",
    "    sensor_colors=sensor_colors,\n",
    "    coord_frame='mri'\n",
    ")\n",
    "\n",
    "# Plot the whole brain in an opaque manner\n",
    "brain = mne.viz.Brain(\n",
    "    subject=subject,\n",
    "    alpha=0.35,\n",
    "    cortex=\"low_contrast\",\n",
    "    subjects_dir=subjects_dir,\n",
    "    units=\"m\",\n",
    "    figure=fig,\n",
    ")\n",
    "\n",
    "# Plot the selected brain regions\n",
    "# brain.add_volume_labels(aseg=\"rh.hippoAmygLabels.HBT.resampled\", labels=labels, lut_fname=lut_fname)\n",
    "# brain.add_volume_labels(aseg=\"lh.hippoAmygLabels.HBT.resampled\", labels=labels, lut_fname=lut_fname)\n",
    "brain.add_volume_labels(aseg=\"hippoAmygLabels.HBT.combined\", labels=labels, lut_fname=lut_fname)\n",
    "# brain.add_volume_labels(aseg=\"aparc+aseg\", labels=labels, lut_fname=lut_fname)\n",
    "brain.show_view(azimuth=120, elevation=90, distance=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to File\n",
    "\n",
    "Now that we have the electrode coordinates inoculated in the MNE-Python Raw object along with the iEEG data readings we will save the results. But, saving the coordinates to file will be saved in head space, therefore we also need to save the correct transformation matrices to go from head to surface RAS space - which is referred to as MRI space inside MNE documentation - as we need the coordinates in MRI space to match the freesurfer surface output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save raw\n",
    "data.raw.save(fname=''.join([path_data, '/sub', subject_id, '_raw_ieeg.fif']), \n",
    "              split_naming='bids', \n",
    "              overwrite=True)\n",
    "\n",
    "# save transformations\n",
    "head2mri_t.save(''.join([subjects_dir, '/', subject, '/mri/transforms/t1-head2mri-trans.fif']), overwrite=True)\n",
    "mri2head_t.save(''.join([subjects_dir, '/', subject, '/mri/transforms/t1-mri2head-trans.fif']), overwrite=True)\n",
    "ras2mri_t.save(''.join([subjects_dir, '/', subject, '/mri/transforms/t1-ras2mri-trans.fif']), overwrite=True)\n",
    "mm2m_t.save(''.join([subjects_dir, '/', subject, '/mri/transforms/t1-mm2m-trans.fif']), overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
