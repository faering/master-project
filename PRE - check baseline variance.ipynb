{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Baseline Variance\n",
    "\n",
    "Prework to determine whether baseline correction should be done within trials or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import neuropsy as npsy\n",
    "import neuropsy.analysis as npsya\n",
    "import pickle\n",
    "import json\n",
    "import pandas\n",
    "import time\n",
    "from scipy import signal\n",
    "from scipy.fftpack import next_fast_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********** PARAMETERS **********#\n",
    "path_data                   = '/mnt/c/Users/matti/OneDrive/Education/SDC/MasterThesis/master-project/data/preprocessed'\n",
    "path_results                = f'/mnt/c/Users/matti/OneDrive/Education/SDC/MasterThesis/master-project/results/preprocessing/check baseline'\n",
    "subject_ids                 = npsy.utils.get_subject_ids_from_path(path_data)\n",
    "\n",
    "postfix_load                = 'preprocessed'\n",
    "\n",
    "# analysis parameters\n",
    "baseline                    = (-.2, 0.)              # time period from before stimulus to use for baseline correction\n",
    "baseline_method             = 'mean'                # basline correction method (see neuropsy.preprocessing)\n",
    "\n",
    "# wavelet parameters\n",
    "fs                          = 512\n",
    "t_wl                        = np.arange(-4, 4+1/fs, 1/fs) # long enough time to capture the wavelet for given f and n\n",
    "# 2-12 Hz, 3-8 cycles\n",
    "frequencies                 = np.arange(2, 13, 1)\n",
    "cycles                      = [8, 7, 6, 6, 5, 5, 5, 4, 4, 3, 3]\n",
    "n_half_wavelet              = len(t_wl) // 2\n",
    "\n",
    "# set up directory for saving results\n",
    "if not os.path.exists(path_results):\n",
    "    os.makedirs(path_results)\n",
    "    os.makedirs(f\"{path_results}/data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Compute Power of Baseline Periods Individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cond_column' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m dict_analysis_info \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      3\u001b[0m dict_analysis_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeneral\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 4\u001b[0m dict_analysis_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeneral\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcond_column\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mcond_column\u001b[49m\n\u001b[1;32m      5\u001b[0m dict_analysis_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeneral\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbaseline\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m baseline\n\u001b[1;32m      6\u001b[0m dict_analysis_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeneral\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbaseline_method\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m baseline_method\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cond_column' is not defined"
     ]
    }
   ],
   "source": [
    "# save general analysis info (will be saved as json file in the end)\n",
    "dict_analysis_info = {}\n",
    "dict_analysis_info['general'] = {}\n",
    "dict_analysis_info['general']['baseline'] = baseline\n",
    "dict_analysis_info['general']['baseline_method'] = baseline_method\n",
    "dict_analysis_info['general']['wavelet'] = {'frequencies': frequencies.tolist(), 'cycles': cycles.tolist() if isinstance(cycles, np.ndarray) else cycles}\n",
    "\n",
    "# time-frequency result dictionary {condition: {subject_id: {channel: {trial: np.2darray}}}}\n",
    "dict_tfr_power_results = {s: {} for s in subject_ids}\n",
    "\n",
    "#********** START ANALYSIS **********#\n",
    "for subject_id in subject_ids:\n",
    "    \n",
    "    # initialise variables\n",
    "    trial_names_outliers                = None\n",
    "    labels_outliers                     = None\n",
    "    dict_outliers                       = {}\n",
    "    trial_names_too_short               = None\n",
    "    trial_names_too_close               = None\n",
    "    labels_too_short                    = None\n",
    "    labels_too_close                    = None\n",
    "    dict_too_short                      = {}\n",
    "    dict_too_close                      = {}\n",
    "    \n",
    "    \n",
    "    start_time_sub = time.time()\n",
    "    print(f\"Starting subject {subject_id}...\")\n",
    "\n",
    "    #********** LOAD SUBJECT DATA **********# \n",
    "    data = npsy.DataHandler(path=path_data, subject_id=subject_id, exp_phase=2, fs=512, verbose=False)\n",
    "    data.load(load_saved=True, postfix=postfix_load)\n",
    "    \n",
    "    # subtract total mean from each channel to remove DC bias\n",
    "    print(\"Removing DC bias from iEEG data...\")\n",
    "    total_mean = np.mean(data.ieeg)\n",
    "    for i in range(data.ieeg.shape[0]):\n",
    "        data.ieeg[i, :] = data.ieeg[i, :] - total_mean\n",
    "        data.ieeg[i, :] = signal.detrend(data.ieeg[i, :])\n",
    "        \n",
    "    #********** SELECT CHANNELS TO INCLUDE IN ANALYSIS **********# \n",
    "    print(f\"Selecting channels in hippocampus...\")\n",
    "    ch_names = data.df_chan.loc[data.df_chan['DK_Subfields'].str.contains('HP_head|HP_body|HP_tail', case=True)].name.to_list()\n",
    "    # check that there are channels in the hippocampal subfield for this subject, otherwise skip\n",
    "    if len(ch_names) > 0:\n",
    "        data.select_channels(ch_names=np.ravel(ch_names), inplace=True)\n",
    "        print(f\"Selected {len(ch_names)} channels in hippocampus.\")\n",
    "    else:\n",
    "        print(f\"No channels in hippocampus.\")\n",
    "    \n",
    "    #********** REMOVE OUTLIERS (TRIALS WITH TOO HIGH REACTION TIME)  **********# \n",
    "    print(\"Removing outliers from experiment dataframe...\")\n",
    "    idx_outliers = data.df_exp[data.df_exp['outlier'] == True]['outlier'].index.to_list()\n",
    "    if len(idx_outliers) > 0:\n",
    "        trial_names_outliers    = data.df_exp[data.df_exp['outlier'] == True]['Trial Identifier'].to_list()\n",
    "        labels_outliers         = data.df_exp.loc[idx_outliers, cond_column].to_list()\n",
    "        for i, label in zip(idx_outliers, labels_outliers):\n",
    "            if label not in dict_outliers.keys():\n",
    "                dict_outliers[label] = 1\n",
    "            else:\n",
    "                dict_outliers[label] += 1\n",
    "        for key, value in dict_outliers.items():\n",
    "            print(f\"{value} outliers in condition {repr(key)}.\")\n",
    "        data.df_exp = data.df_exp.drop(idx_outliers).reset_index(drop=True)\n",
    "    else:\n",
    "        print(\"No outliers in experiment dataframe.\")\n",
    "\n",
    "    #********** CREATE MNE RAW OBJECT WITH iEEG DATA **********#\n",
    "    data.create_raw()\n",
    "    \n",
    "\n",
    "    #********** GET TRIAL TIME POINTS (INDICES) AND TRIAL IDENTIFIERS (NAMES) **********#\n",
    "    # - need trial indices from experiment dataframe to extract the baseline period for each trial\n",
    "    # - also need to extract the trial identifiers (names) to keep track of trials in the resulting time-frequency power data\n",
    "    print(\"Getting trial indices...\")\n",
    "    dict_trial_indices = {**{f'baseline': None}, **{f'names': None}}\n",
    "    # get the trial indices\n",
    "    idx_baseline                    = data.df_exp['Mark for Picture Shown'].to_numpy().astype(int)\n",
    "    # save indices\n",
    "    dict_trial_indices[\"baseline\"]  = idx_baseline\n",
    "    # get the trial identifiers (names) for the condition\n",
    "    trial_names                     = data.df_exp['Trial Identifier'].to_numpy().astype(str)\n",
    "    # save trial identifiers\n",
    "    dict_trial_indices[\"names\"]     = trial_names\n",
    "\n",
    "\n",
    "    #********** TIME-FREQUENCY ANALYSIS **********#\n",
    "    # info\n",
    "    dict_n_trials_kept = None\n",
    "    dict_n_trials_ieds = None\n",
    "    \n",
    "    if len(ch_names) > 0:\n",
    "        \n",
    "        # info\n",
    "        dict_n_trials_kept = {**{f'{ch}': {'trial_identifiers': [], 'count': None} for ch in ch_names}, **{'total': 0}}\n",
    "        dict_n_trials_ieds = {**{f'{ch}': {'trial_identifiers': [], 'count': None} for ch in ch_names}, **{'total': 0}}\n",
    "        \n",
    "        # CHANNEL:\n",
    "        #  - FFT of entire channel signal\n",
    "        #  - CWT for each frequency and cycle\n",
    "        #  - store power in dB for each frequency\n",
    "        #  - this is done once per channel, then afterwards each trial is considered independently during CONDITION loop\n",
    "        #    - this is done to save time as the CWT is the most time-consuming part\n",
    "        for ch in ch_names:\n",
    "            start_time_ch = time.time()\n",
    "            print(f\"\\tStarting channel {ch}...\")\n",
    "            \n",
    "            # use the whole channel signal for computing time-frequency representation\n",
    "            ch_signal = data.raw._data[ch_names.index(ch), ...]\n",
    "            \n",
    "            # ********* FFT of CHANNEL ********* #\n",
    "            n_conv      = len(t_wl) + len(ch_signal) - 1\n",
    "            n_conv_fast = next_fast_len(n_conv)\n",
    "            signal_fft  = np.fft.fft(ch_signal, n_conv_fast)\n",
    "            \n",
    "            # initialise output data for continuous wavelet transform\n",
    "            tf_data = np.zeros((len(frequencies), len(ch_signal)))\n",
    "            \n",
    "            # ********* CWT ********* #\n",
    "            for i, (f, n) in enumerate(zip(frequencies, cycles)):\n",
    "                \n",
    "                # [INFO] - print current wavelet parameters\n",
    "                # print(f\"creating wavelet with parameters: f = {f}, n = {n}...\")\n",
    "                \n",
    "                # create wavelet\n",
    "                wavelet = npsya.morlet(f, n, t_wl)\n",
    "                \n",
    "                # fft of wavelet\n",
    "                # note:\n",
    "                #   output must match the length of the signal_fft in order to multiply in the frequency domain\n",
    "                wavelet_fft = np.fft.fft(wavelet, n=n_conv_fast)\n",
    "                \n",
    "                # convolution\n",
    "                coefficients = np.fft.ifft(signal_fft * wavelet_fft, n=n_conv_fast)\n",
    "                coefficients = coefficients[:n_conv] # remove padding from next_fast_len\n",
    "                coefficients = coefficients[n_half_wavelet:-n_half_wavelet]\n",
    "                \n",
    "                # convert to power in dB\n",
    "                tf_power = 10 * np.log10(np.abs(coefficients)**2)\n",
    "                \n",
    "                # store result for frequency\n",
    "                tf_data[i, :] = tf_power\n",
    "                \n",
    "            # clean up\n",
    "            del ch_signal, signal_fft, wavelet, wavelet_fft, coefficients, tf_power\n",
    "                \n",
    "            # CONDITION:\n",
    "            #  - continuous wavelet transform result is stored in tf_data (in dB)\n",
    "            #  - now we need to consider each trial independently\n",
    "            #  - loop over conditions\n",
    "            #  - loop over trials in condition\n",
    "            #  - baseline correction is done for each trial separately\n",
    "            #  - the window between onset and offset is divided into bins\n",
    "            \n",
    "            dict_tfr_power_results[subject_id][ch] = {}\n",
    "            \n",
    "            for (i_baseline, trial_id) in zip(dict_trial_indices[f'baseline'], \n",
    "                                                dict_trial_indices[f'names']):\n",
    "                start_time_trial = time.time()\n",
    "                \n",
    "                # get start and stop timepoints for baseline period\n",
    "                b_tmin = int(i_baseline + int(baseline[0] * fs))\n",
    "                b_tmax = int(i_baseline + int(baseline[1] * fs))\n",
    "                \n",
    "                #********** CHECK TRIAL FOR IEDs **********# \n",
    "                # - if there are IEDs in the baseline, skip it and exclude it from the analysis\n",
    "                if npsya.check_period_for_ieds(ch, data.df_ied, b_tmin, b_tmax):\n",
    "                    print(f\"\\t\\t\\tSkipping trial {trial_id} due to IEDs in baseline period.\")\n",
    "                    dict_n_trials_ieds[ch]['trial_identifiers'].append(trial_id)\n",
    "                    dict_n_trials_ieds[ch]['count'] += 1\n",
    "                    dict_n_trials_ieds['total']     += 1\n",
    "                    continue\n",
    "                \n",
    "                # get power for baseline period\n",
    "                power_baseline = tf_data[:, b_tmin:b_tmax]\n",
    "                \n",
    "                # calculate mean of baseline across time, vector output = [freq_dim,]\n",
    "                power_baseline_mean = np.mean(power_baseline, axis=1)\n",
    "                \n",
    "                # store time-frequency power result for trial\n",
    "                dict_tfr_power_results[subject_id][ch][trial_id] = power_baseline_mean\n",
    "                \n",
    "                # info\n",
    "                dict_n_trials_kept[ch]['trial_identifiers'].append(trial_id)\n",
    "                dict_n_trials_kept[ch]['count'] += 1\n",
    "                dict_n_trials_kept['total']     += 1\n",
    "                \n",
    "            # clean up\n",
    "            del power_baseline\n",
    "            print(f\"\\tChannel {ch} done - {time.time() - start_time_ch:.2f} seconds\")\n",
    "    # no channels\n",
    "    else:\n",
    "        # remove subject from results if there are no channels in the hippocampus\n",
    "        dict_tfr_power_results.pop(subject_id)\n",
    "        print(f\"No channels in hippocampus for subject {subject_id}.\")\n",
    "        \n",
    "\n",
    "    # save analysis info for subject\n",
    "    tmp_dict_outliers           = {**dict_outliers, **{'count': len(idx_outliers)}, **{'indices': idx_outliers}, **{'trial_identifiers': trial_names_outliers}}\n",
    "    \n",
    "    dict_analysis_info[f'subject {subject_id}'] = {\n",
    "        'channels': ch_names if len(ch_names) > 0 else None,\n",
    "        'trials_kept': dict_n_trials_kept,\n",
    "        'trials_dropped': {\n",
    "            'outliers': tmp_dict_outliers,\n",
    "            'ieds': dict_n_trials_ieds\n",
    "        } if len(ch_names) > 0 else None\n",
    "    }\n",
    "    \n",
    "    # clean up\n",
    "    del dict_n_trials_kept, dict_n_trials_ieds, tmp_dict_outliers\n",
    "    \n",
    "    print(f\"Subject {subject_id} done - {time.time() - start_time_sub:.2f} seconds\")\n",
    "    \n",
    "    # break\n",
    "        \n",
    "\n",
    "#********** SAVE RESULTS **********#\n",
    "filename = f\"{path_results}/data/baseline_mean_power.pkl\"\n",
    "with open(filename, 'wb') as f:\n",
    "    print(f\"Saving results as {repr(filename)}...\")\n",
    "    pickle.dump(dict_tfr_power_results, f)\n",
    "    print(\"Done\")\n",
    "#********** SAVE ANALYSIS INFO **********#\n",
    "filename = f\"{path_results}/data/baseline_analysis_info.json\"\n",
    "with open(filename, 'w') as f:\n",
    "    print(f\"Saving analysis info as {repr(filename)}...\")\n",
    "    json.dump(dict_analysis_info, f)\n",
    "    print(\"Done\")\n",
    "    \n",
    "# clean up\n",
    "del dict_tfr_power_results, dict_analysis_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Plot Baseline Variance Across Trials\n",
    "\n",
    "- Each subject is processed independently\n",
    "- Each frequency is processed indpendently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [INFO] load data in this cell once to avoid re-running the heavy loading process. \n",
    "filename = f\"{path_results}/data/baseline_mean_power.pkl\"\n",
    "\n",
    "# load previously computed time-frequency power for all subjects\n",
    "with open(filename, 'rb') as f:\n",
    "    dict_baseline_mean_power = pickle.load(f)\n",
    "    \n",
    "# get conditions and subject ids from the loaded results dictionary\n",
    "subject_ids = list(dict_baseline_mean_power.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 03, channel B' 02: 193 trials.\n",
      "Subject 03, channel B' 03: 192 trials.\n",
      "Subject 03, channel B' 04: 190 trials.\n",
      "Subject 03, channel B' 05: 192 trials.\n",
      "Subject 03, channel C' 02: 194 trials.\n"
     ]
    }
   ],
   "source": [
    "# [INFO] NOT USED!!!\n",
    "\n",
    "\n",
    "# get conditions and subject ids from the loaded results dictionary\n",
    "subject_ids = list(dict_baseline_mean_power.keys())\n",
    "\n",
    "list_baseline_power = []\n",
    "for i, sub_id in enumerate(subject_ids):\n",
    "    list_baseline_power.append([])\n",
    "    \n",
    "    for j, channel in enumerate(dict_baseline_mean_power[sub_id].keys()):\n",
    "        list_baseline_power[i].append([])\n",
    "        \n",
    "        print(f\"Subject {sub_id}, channel {channel}: {len(dict_baseline_mean_power[sub_id][channel].keys())} trials.\")\n",
    "        \n",
    "        for f in range(n_freqs):\n",
    "            list_baseline_power[i][j].append([])\n",
    "        \n",
    "            for trial in dict_baseline_mean_power[sub_id][channel].keys():\n",
    "                \n",
    "                list_baseline_power[i][j][f].append(dict_baseline_mean_power[sub_id][channel][trial][f])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved figure as /mnt/c/Users/matti/OneDrive/Education/SDC/MasterThesis/master-project/results/preprocessing/check baseline/boxplot_sub03.png\n",
      "Saved figure as /mnt/c/Users/matti/OneDrive/Education/SDC/MasterThesis/master-project/results/preprocessing/check baseline/boxplot_sub04.png\n",
      "Saved figure as /mnt/c/Users/matti/OneDrive/Education/SDC/MasterThesis/master-project/results/preprocessing/check baseline/boxplot_sub05.png\n",
      "Saved figure as /mnt/c/Users/matti/OneDrive/Education/SDC/MasterThesis/master-project/results/preprocessing/check baseline/boxplot_sub07.png\n",
      "Saved figure as /mnt/c/Users/matti/OneDrive/Education/SDC/MasterThesis/master-project/results/preprocessing/check baseline/boxplot_sub09.png\n",
      "Saved figure as /mnt/c/Users/matti/OneDrive/Education/SDC/MasterThesis/master-project/results/preprocessing/check baseline/boxplot_sub10.png\n",
      "Saved figure as /mnt/c/Users/matti/OneDrive/Education/SDC/MasterThesis/master-project/results/preprocessing/check baseline/boxplot_sub11.png\n",
      "Saved figure as /mnt/c/Users/matti/OneDrive/Education/SDC/MasterThesis/master-project/results/preprocessing/check baseline/boxplot_sub12.png\n",
      "Saved figure as /mnt/c/Users/matti/OneDrive/Education/SDC/MasterThesis/master-project/results/preprocessing/check baseline/boxplot_sub14.png\n",
      "Saved figure as /mnt/c/Users/matti/OneDrive/Education/SDC/MasterThesis/master-project/results/preprocessing/check baseline/boxplot_sub15.png\n",
      "Saved figure as /mnt/c/Users/matti/OneDrive/Education/SDC/MasterThesis/master-project/results/preprocessing/check baseline/boxplot_sub19.png\n"
     ]
    }
   ],
   "source": [
    "for sub_id in subject_ids:\n",
    "    fig, ax = plt.subplots(nrows=3, ncols=4, figsize=(25, 15))\n",
    "    ax = ax.flatten()\n",
    "    \n",
    "    for f, freq in enumerate(frequencies):\n",
    "        channel_baseline_power = []\n",
    "        channel_names = []\n",
    "        \n",
    "        for ch, channel in enumerate(dict_baseline_mean_power[sub_id].keys()):\n",
    "            trials_baseline_power = []\n",
    "            channel_names.append(channel)\n",
    "            \n",
    "            for trial in dict_baseline_mean_power[sub_id][channel].keys():\n",
    "                trials_baseline_power.append(dict_baseline_mean_power[sub_id][channel][trial][f])\n",
    "                \n",
    "            channel_baseline_power.append(trials_baseline_power)\n",
    "        \n",
    "        # plot\n",
    "        channel_baseline_power = np.array(channel_baseline_power, dtype=object)\n",
    "        ax[f].boxplot([ch for ch in channel_baseline_power], labels=channel_names)\n",
    "        ax[f].set_title(f\"Frequency: {freq} Hz\")\n",
    "        # ax[f].grid(axis='y')\n",
    "    \n",
    "    ax[11].axis('off')\n",
    "    \n",
    "    fig.suptitle(f\"Subject {sub_id} - Baseline Variance\", fontsize=14, y=.92)\n",
    "    \n",
    "    # save figure\n",
    "    full_save_path = f\"{path_results}/2.1 boxplot_sub{sub_id}\"\n",
    "    fig.savefig(full_save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Saved figure as {full_save_path}.png\")\n",
    "    plt.close(fig)\n",
    "                \n",
    "    # break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Lineplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved figure as /mnt/c/Users/matti/OneDrive/Education/SDC/MasterThesis/master-project/results/preprocessing/check baseline/lineplot_sub15_channel_B' 02.png\n",
      "Saved figure as /mnt/c/Users/matti/OneDrive/Education/SDC/MasterThesis/master-project/results/preprocessing/check baseline/lineplot_sub15_channel_B' 03.png\n",
      "Saved figure as /mnt/c/Users/matti/OneDrive/Education/SDC/MasterThesis/master-project/results/preprocessing/check baseline/lineplot_sub15_channel_B' 04.png\n",
      "Saved figure as /mnt/c/Users/matti/OneDrive/Education/SDC/MasterThesis/master-project/results/preprocessing/check baseline/lineplot_sub15_channel_B' 05.png\n",
      "Saved figure as /mnt/c/Users/matti/OneDrive/Education/SDC/MasterThesis/master-project/results/preprocessing/check baseline/lineplot_sub15_channel_B' 06.png\n",
      "Saved figure as /mnt/c/Users/matti/OneDrive/Education/SDC/MasterThesis/master-project/results/preprocessing/check baseline/lineplot_sub15_channel_C' 02.png\n",
      "Saved figure as /mnt/c/Users/matti/OneDrive/Education/SDC/MasterThesis/master-project/results/preprocessing/check baseline/lineplot_sub15_channel_C' 03.png\n",
      "Saved figure as /mnt/c/Users/matti/OneDrive/Education/SDC/MasterThesis/master-project/results/preprocessing/check baseline/lineplot_sub15_channel_C' 04.png\n",
      "Saved figure as /mnt/c/Users/matti/OneDrive/Education/SDC/MasterThesis/master-project/results/preprocessing/check baseline/lineplot_sub19_channel_B 02.png\n",
      "Saved figure as /mnt/c/Users/matti/OneDrive/Education/SDC/MasterThesis/master-project/results/preprocessing/check baseline/lineplot_sub19_channel_B 03.png\n",
      "Saved figure as /mnt/c/Users/matti/OneDrive/Education/SDC/MasterThesis/master-project/results/preprocessing/check baseline/lineplot_sub19_channel_B' 02.png\n",
      "Saved figure as /mnt/c/Users/matti/OneDrive/Education/SDC/MasterThesis/master-project/results/preprocessing/check baseline/lineplot_sub19_channel_B' 03.png\n",
      "Saved figure as /mnt/c/Users/matti/OneDrive/Education/SDC/MasterThesis/master-project/results/preprocessing/check baseline/lineplot_sub19_channel_C' 02.png\n",
      "Saved figure as /mnt/c/Users/matti/OneDrive/Education/SDC/MasterThesis/master-project/results/preprocessing/check baseline/lineplot_sub19_channel_C' 03.png\n",
      "Saved figure as /mnt/c/Users/matti/OneDrive/Education/SDC/MasterThesis/master-project/results/preprocessing/check baseline/lineplot_sub19_channel_C' 04.png\n"
     ]
    }
   ],
   "source": [
    "def normalize(data, new_min=0, new_max=1):\n",
    "    min_val = np.min(data)\n",
    "    max_val = np.max(data)\n",
    "    normalized = (data - min_val) / (max_val - min_val) * (new_max - new_min) + new_min\n",
    "    return normalized\n",
    "\n",
    "\n",
    "for sub_id in subject_ids:        \n",
    "    for channel in dict_baseline_mean_power[sub_id].keys():\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(25, 10))\n",
    "        \n",
    "        trials_baseline_power = []\n",
    "        for trial in dict_baseline_mean_power[sub_id][channel].keys():\n",
    "            trials_baseline_power.append(dict_baseline_mean_power[sub_id][channel][trial])\n",
    "            \n",
    "        trials_baseline_power = np.array(trials_baseline_power)    \n",
    "        \n",
    "        for f, freq in enumerate(frequencies):\n",
    "            trials_baseline_power[:, f] = normalize(trials_baseline_power[:, f], new_min=freq-1, new_max=freq+1)\n",
    "        \n",
    "        ax.plot(trials_baseline_power)\n",
    "        ax.set_title(f\"Subject {sub_id} - channel {channel} - Baseline Variance\", fontsize=14)\n",
    "        ax.set_ylabel(\"Frequency (Hz)\", fontsize=12)\n",
    "        ax.set_xlabel(\"Trial\", fontsize=12)\n",
    "        \n",
    "        ax.set_yticks(frequencies, frequencies)\n",
    "        ax.set_xlim((0, len(trials_baseline_power)-1))\n",
    "        ax.grid(axis='y')\n",
    "        \n",
    "        # save figure\n",
    "        full_save_path = f\"{path_results}/2.2 lineplot_sub{sub_id}_channel_{channel}\"\n",
    "        fig.savefig(full_save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Saved figure as {full_save_path}.png\")\n",
    "        plt.close(fig)\n",
    "        \n",
    "    #     break\n",
    "    # break    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdcmaster",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
